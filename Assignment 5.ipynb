{"cells":[{"cell_type":"markdown","metadata":{},"source":["Shubh Agarwal \n","AIML B2\n","22070126108 "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:19:36.191655Z","iopub.status.busy":"2024-10-24T09:19:36.191240Z","iopub.status.idle":"2024-10-24T09:19:43.516084Z","shell.execute_reply":"2024-10-24T09:19:43.515138Z","shell.execute_reply.started":"2024-10-24T09:19:36.191602Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Using device: cuda\n"]}],"source":["# Imports\n","import json\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import (\n","    \n","    T5Tokenizer, T5ForConditionalGeneration,\n","    DistilBertTokenizer, DistilBertForQuestionAnswering,\n","    GPT2Tokenizer, GPT2LMHeadModel,\n","    AdamW\n",")\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","\n","from nltk.translate.bleu_score import sentence_bleu\n","import nltk\n","import logging\n","\n","# Download NLTK data for BLEU score calculation\n","nltk.download('punkt')\n","\n","# Ignore Warnings\n","logging.disable(logging.WARNING)\n","\n","# Device setup: Use GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:03:36.762283Z","iopub.status.busy":"2024-10-24T09:03:36.761841Z","iopub.status.idle":"2024-10-24T09:03:42.038275Z","shell.execute_reply":"2024-10-24T09:03:42.037325Z","shell.execute_reply.started":"2024-10-24T09:03:36.762246Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting nltk\n","  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.4.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.66.5)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2024.9.11)\n","Installing collected packages: nltk\n","Successfully installed nltk-3.9.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install nltk"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:19:46.397503Z","iopub.status.busy":"2024-10-24T09:19:46.396691Z","iopub.status.idle":"2024-10-24T09:19:47.659763Z","shell.execute_reply":"2024-10-24T09:19:47.658820Z","shell.execute_reply.started":"2024-10-24T09:19:46.397425Z"},"trusted":true},"outputs":[],"source":["# Load CoQA dataset\n","def load_coqa_data(file_path):\n","    with open(file_path, 'r') as f:\n","        data = json.load(f)\n","    return data['data']\n","\n","# Load the data\n","data = load_coqa_data('/kaggle/input/coqa-train-v/coqa-train-v1.0.json')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:19:50.469185Z","iopub.status.busy":"2024-10-24T09:19:50.468883Z","iopub.status.idle":"2024-10-24T09:19:50.488103Z","shell.execute_reply":"2024-10-24T09:19:50.487124Z","shell.execute_reply.started":"2024-10-24T09:19:50.469149Z"},"trusted":true},"outputs":[],"source":["# Custom dataset class\n","class CoQADataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length=512, model_type='bert'):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.model_type = model_type\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        context = item['story']\n","        question = item['questions'][0]['input_text']\n","        answer = item['answers'][0]['input_text']\n","\n","        if self.model_type == 't5':\n","            # For T5, we format the input as text-to-text\n","            input_text = f\"question: {question} context: {context}\"\n","            target_text = answer\n","\n","            # Tokenize inputs and targets\n","            input_ids = self.tokenizer.encode(\n","                input_text,\n","                max_length=self.max_length,\n","                padding='max_length',\n","                truncation=True,\n","                return_tensors='pt'\n","            ).squeeze()\n","\n","            target_ids = self.tokenizer.encode(\n","                target_text,\n","                max_length=self.max_length // 4,\n","                padding='max_length',\n","                truncation=True,\n","                return_tensors='pt'\n","            ).squeeze()\n","\n","            return {\n","                'input_ids': input_ids,\n","                'attention_mask': (input_ids != self.tokenizer.pad_token_id).long(),\n","                'labels': target_ids,\n","                'answer': answer\n","            }\n","\n","        elif self.model_type == 'gpt2':\n","            # For GPT-2, we prepare input for language modeling\n","            input_text = f\"Question: {question} Context: {context} Answer:\"\n","            target_text = answer\n","\n","            # Concatenate input and target for GPT-2\n","            full_text = input_text + \" \" + target_text\n","\n","            input_ids = self.tokenizer.encode(\n","                full_text,\n","                max_length=self.max_length,\n","                padding='max_length',\n","                truncation=True,\n","                return_tensors='pt'\n","            ).squeeze()\n","\n","            return {\n","                'input_ids': input_ids,\n","                'attention_mask': (input_ids != self.tokenizer.pad_token_id).long(),\n","                'labels': input_ids,\n","                'answer': answer\n","            }\n","\n","        else:\n","            # For BERT and DistilBERT (extractive QA models)\n","            # Tokenize the input\n","            inputs = self.tokenizer.encode_plus(\n","                question,\n","                context,\n","                add_special_tokens=True,\n","                max_length=self.max_length,\n","                padding='max_length',\n","                truncation=True,\n","                return_tensors='pt'\n","            )\n","\n","            # Find the start and end positions of the answer in the tokenized input\n","            input_ids = inputs['input_ids'].squeeze()\n","            attention_mask = inputs['attention_mask'].squeeze()\n","            token_type_ids = inputs.get('token_type_ids', None)\n","            if token_type_ids is not None:\n","                token_type_ids = token_type_ids.squeeze()\n","\n","            answer_tokens = self.tokenizer.encode(answer, add_special_tokens=False)\n","            start_position = None\n","            end_position = None\n","\n","            for i in range(len(input_ids) - len(answer_tokens) + 1):\n","                if input_ids[i:i+len(answer_tokens)].tolist() == answer_tokens:\n","                    start_position = i\n","                    end_position = i + len(answer_tokens) - 1\n","                    break\n","\n","            # If the answer is not found, use the CLS token position as a default\n","            if start_position is None:\n","                start_position = 0\n","                end_position = 0\n","\n","            item = {\n","                'input_ids': input_ids,\n","                'attention_mask': attention_mask,\n","                'start_positions': torch.tensor(start_position),\n","                'end_positions': torch.tensor(end_position),\n","                'answer': answer\n","            }\n","            if token_type_ids is not None:\n","                item['token_type_ids'] = token_type_ids\n","\n","            return item\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:19:54.664593Z","iopub.status.busy":"2024-10-24T09:19:54.663822Z","iopub.status.idle":"2024-10-24T09:19:54.679786Z","shell.execute_reply":"2024-10-24T09:19:54.678443Z","shell.execute_reply.started":"2024-10-24T09:19:54.664532Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train samples: 5039\n","Validation samples: 1080\n","Test samples: 1080\n"]}],"source":["# Split the data\n","train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n","val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n","\n","print(f\"Train samples: {len(train_data)}\")\n","print(f\"Validation samples: {len(val_data)}\")\n","print(f\"Test samples: {len(test_data)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:19:58.186470Z","iopub.status.busy":"2024-10-24T09:19:58.186181Z","iopub.status.idle":"2024-10-24T09:20:11.053130Z","shell.execute_reply":"2024-10-24T09:20:11.052267Z","shell.execute_reply.started":"2024-10-24T09:19:58.186425Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n"]}],"source":["!pip install sentencepiece\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:07:15.065790Z","iopub.status.busy":"2024-10-24T09:07:15.064833Z","iopub.status.idle":"2024-10-24T09:07:20.609445Z","shell.execute_reply":"2024-10-24T09:07:20.608510Z","shell.execute_reply.started":"2024-10-24T09:07:15.065751Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\n","Collecting pip\n","  Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.0.1\n","    Uninstalling pip-23.0.1:\n","      Successfully uninstalled pip-23.0.1\n","Successfully installed pip-24.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install --upgrade pip"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:07:37.986637Z","iopub.status.busy":"2024-10-24T09:07:37.985648Z","iopub.status.idle":"2024-10-24T09:07:39.892010Z","shell.execute_reply":"2024-10-24T09:07:39.891012Z","shell.execute_reply.started":"2024-10-24T09:07:37.986599Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (0.2.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install --upgrade sentencepiece\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:04:40.464568Z","iopub.status.busy":"2024-10-24T09:04:40.463979Z","iopub.status.idle":"2024-10-24T09:04:55.604067Z","shell.execute_reply":"2024-10-24T09:04:55.603011Z","shell.execute_reply.started":"2024-10-24T09:04:40.464534Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (4.45.1)\n","Collecting transformers\n","  Downloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (0.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/site-packages (from transformers) (0.25.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers) (3.16.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/site-packages (from transformers) (0.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers) (4.66.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers) (24.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.45.1\n","    Uninstalling transformers-4.45.1:\n","      Successfully uninstalled transformers-4.45.1\n","Successfully installed transformers-4.46.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install --upgrade --no-cache-dir transformers sentencepiece\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:05:09.768781Z","iopub.status.busy":"2024-10-24T09:05:09.768154Z","iopub.status.idle":"2024-10-24T09:05:09.793670Z","shell.execute_reply":"2024-10-24T09:05:09.792947Z","shell.execute_reply.started":"2024-10-24T09:05:09.768742Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.2.0\n"]}],"source":["import sentencepiece as spm\n","print(spm.__version__)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:20:30.325352Z","iopub.status.busy":"2024-10-24T09:20:30.325043Z","iopub.status.idle":"2024-10-24T09:20:36.896178Z","shell.execute_reply":"2024-10-24T09:20:36.895461Z","shell.execute_reply.started":"2024-10-24T09:20:30.325312Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46d5f97816b345e393bd50bd2aabe522","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5e3a71b57324b04a6832ed10543bb9c","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0a45544b7454f95b5ca2e34789aaf51","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03db7dbe98354ecda06d82d520bc1b61","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f2a8882ebca4c9da822d41bd47cf763","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize tokenizer and model\n","t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","t5_model = T5ForConditionalGeneration.from_pretrained('t5-base').to(device)\n","\n","# Prepare datasets and dataloaders\n","train_dataset_t5 = CoQADataset(train_data, t5_tokenizer, model_type='t5')\n","val_dataset_t5 = CoQADataset(val_data, t5_tokenizer, model_type='t5')\n","test_dataset_t5 = CoQADataset(test_data, t5_tokenizer, model_type='t5')\n","\n","train_loader_t5 = DataLoader(train_dataset_t5, batch_size=4, shuffle=True)\n","val_loader_t5 = DataLoader(val_dataset_t5, batch_size=4)\n","test_loader_t5 = DataLoader(test_dataset_t5, batch_size=4)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:20:52.918344Z","iopub.status.busy":"2024-10-24T09:20:52.918005Z","iopub.status.idle":"2024-10-24T09:20:52.929431Z","shell.execute_reply":"2024-10-24T09:20:52.928145Z","shell.execute_reply.started":"2024-10-24T09:20:52.918298Z"},"trusted":true},"outputs":[],"source":["# Training function\n","def train_t5(model, train_loader, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    progress_bar = tqdm(train_loader, desc=\"Training T5\")\n","    for batch in progress_bar:\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            labels=labels\n","        )\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        progress_bar.set_postfix({'loss': loss.item()})\n","\n","    return total_loss / len(train_loader)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:20:57.212093Z","iopub.status.busy":"2024-10-24T09:20:57.211808Z","iopub.status.idle":"2024-10-24T09:20:57.219516Z","shell.execute_reply":"2024-10-24T09:20:57.218487Z","shell.execute_reply.started":"2024-10-24T09:20:57.212055Z"},"trusted":true},"outputs":[],"source":["# Validation function\n","def validate_t5(model, val_loader, device):\n","    model.eval()\n","    total_loss = 0\n","    progress_bar = tqdm(val_loader, desc=\"Validating T5\")\n","    with torch.no_grad():\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                labels=labels\n","            )\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","\n","            progress_bar.set_postfix({'loss': loss.item()})\n","\n","    return total_loss / len(val_loader)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:21:02.237234Z","iopub.status.busy":"2024-10-24T09:21:02.236474Z","iopub.status.idle":"2024-10-24T09:21:14.509876Z","shell.execute_reply":"2024-10-24T09:21:14.509037Z","shell.execute_reply.started":"2024-10-24T09:21:02.237189Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\n","Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.29.4)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.6.9)\n","Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\n","Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.2)\n","Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.1)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.7.2)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.3)\n","Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (26.0.3)\n","Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.1)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\n","Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n","Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.6.2)\n","Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (1.2.0)\n","Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n","Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n","Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.11.0)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n","Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n","Requirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.5)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.1.2)\n","Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.4.1)\n","Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n","Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n","Requirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n","Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n","Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.5)\n","Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\n","Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.22.0)\n","Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n","Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /opt/conda/lib/python3.10/site-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.12.5)\n","Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\n","Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n","Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.4.0)\n","Requirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n","Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\n","Requirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n","Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7)\n","Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.2)\n","Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.7)\n","Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.2)\n","Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n","Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n","Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n","Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n","Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4)\n","Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n","Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.6.0)\n","Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n","Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.9.0.20240316)\n"]}],"source":["!pip install ipywidgets\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:23:07.241493Z","iopub.status.busy":"2024-10-24T09:23:07.240593Z","iopub.status.idle":"2024-10-24T09:53:19.324824Z","shell.execute_reply":"2024-10-24T09:53:19.323712Z","shell.execute_reply.started":"2024-10-24T09:23:07.241437Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n"]},{"name":"stderr","output_type":"stream","text":["Training T5: 100%|██████████| 1260/1260 [13:59<00:00,  1.50it/s, loss=0.0352] \n","Validating T5: 100%|██████████| 270/270 [01:02<00:00,  4.34it/s, loss=0.0438] \n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.4914, Validation Loss: 0.0385\n","Model saved!\n","**************************************************\n","Epoch 2/2\n"]},{"name":"stderr","output_type":"stream","text":["Training T5: 100%|██████████| 1260/1260 [14:04<00:00,  1.49it/s, loss=0.0359] \n","Validating T5: 100%|██████████| 270/270 [01:02<00:00,  4.35it/s, loss=0.0427] \n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0355, Validation Loss: 0.0322\n","Model saved!\n","**************************************************\n"]}],"source":["# Set optimizer\n","optimizer_t5 = AdamW(t5_model.parameters(), lr=3e-5)\n","\n","# Training loop\n","num_epochs = 2\n","best_loss = float('inf')\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train_loss = train_t5(t5_model, train_loader_t5, optimizer_t5, device)\n","    val_loss = validate_t5(t5_model, val_loader_t5, device)\n","    print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        torch.save(t5_model.state_dict(), 't5_qa_model.pth')\n","        print(\"Model saved!\")\n","    else:\n","        print(\"Validation Loss Increased. Model Not Saved.\")\n","    print(\"*\" * 50)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:54:45.855147Z","iopub.status.busy":"2024-10-24T09:54:45.854434Z","iopub.status.idle":"2024-10-24T09:54:45.862460Z","shell.execute_reply":"2024-10-24T09:54:45.861557Z","shell.execute_reply.started":"2024-10-24T09:54:45.855103Z"},"trusted":true},"outputs":[],"source":["# Testing function\n","def test_t5(model, test_loader, tokenizer, device):\n","    model.eval()\n","    all_predictions = []\n","    all_answers = []\n","    progress_bar = tqdm(test_loader, desc=\"Testing T5\")\n","    with torch.no_grad():\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            answers = batch['answer']\n","\n","            outputs = model.generate(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                max_length=50\n","            )\n","\n","            predictions = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n","            all_predictions.extend(predictions)\n","            all_answers.extend(answers)\n","\n","    bleu_score = calculate_bleu(all_predictions, all_answers)\n","    return bleu_score\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:56:50.774337Z","iopub.status.busy":"2024-10-24T09:56:50.773540Z","iopub.status.idle":"2024-10-24T09:56:50.870109Z","shell.execute_reply":"2024-10-24T09:56:50.869294Z","shell.execute_reply.started":"2024-10-24T09:56:50.774293Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: Who was a major influence on the theory on world travel?\n","Answer: Napoleon\n"]}],"source":["# Create a simple QA bot\n","def qa_bot_t5(context, question):\n","    input_text = f\"question: {question} context: {context}\"\n","    input_ids = t5_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True).to(device)\n","\n","    with torch.no_grad():\n","        outputs = t5_model.generate(input_ids=input_ids, max_length=50)\n","        answer = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return answer\n","\n","# Example usage of the QA bot\n","context = test_data[0]['story']\n","question = test_data[0]['questions'][0]['input_text']\n","answer = qa_bot_t5(context, question)\n","print(f\"Question: {question}\")\n","print(f\"Answer: {answer}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:56:58.462258Z","iopub.status.busy":"2024-10-24T09:56:58.461976Z","iopub.status.idle":"2024-10-24T09:57:01.104744Z","shell.execute_reply":"2024-10-24T09:57:01.103861Z","shell.execute_reply.started":"2024-10-24T09:56:58.462221Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f3c0ba1ca4149d2a5bec3b9bb95245f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c3548bf4f6d4e5faacdf9d3b374fedb","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b457a541d6a482c83513523d4f8e95a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"863831a05d00410791897f9b7721da61","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fddc32246e241e28b7f4a3b1db2386c","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize tokenizer and model\n","distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","distilbert_model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased').to(device)\n","\n","# Prepare datasets and dataloaders\n","train_dataset_distilbert = CoQADataset(train_data, distilbert_tokenizer, model_type='bert')\n","val_dataset_distilbert = CoQADataset(val_data, distilbert_tokenizer, model_type='bert')\n","test_dataset_distilbert = CoQADataset(test_data, distilbert_tokenizer, model_type='bert')\n","\n","train_loader_distilbert = DataLoader(train_dataset_distilbert, batch_size=8, shuffle=True)\n","val_loader_distilbert = DataLoader(val_dataset_distilbert, batch_size=8)\n","test_loader_distilbert = DataLoader(test_dataset_distilbert, batch_size=8)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:57:04.262874Z","iopub.status.busy":"2024-10-24T09:57:04.262070Z","iopub.status.idle":"2024-10-24T09:57:04.270052Z","shell.execute_reply":"2024-10-24T09:57:04.269180Z","shell.execute_reply.started":"2024-10-24T09:57:04.262819Z"},"trusted":true},"outputs":[],"source":["# Training function\n","def train_distilbert(model, train_loader, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    progress_bar = tqdm(train_loader, desc=\"Training DistilBERT\")\n","    for batch in progress_bar:\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        start_positions = batch['start_positions'].to(device)\n","        end_positions = batch['end_positions'].to(device)\n","\n","        outputs = model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            start_positions=start_positions,\n","            end_positions=end_positions\n","        )\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        progress_bar.set_postfix({'loss': loss.item()})\n","\n","    return total_loss / len(train_loader)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:57:08.059359Z","iopub.status.busy":"2024-10-24T09:57:08.058820Z","iopub.status.idle":"2024-10-24T09:57:08.066385Z","shell.execute_reply":"2024-10-24T09:57:08.065457Z","shell.execute_reply.started":"2024-10-24T09:57:08.059320Z"},"trusted":true},"outputs":[],"source":["# Validation function\n","def validate_distilbert(model, val_loader, device):\n","    model.eval()\n","    total_loss = 0\n","    progress_bar = tqdm(val_loader, desc=\"Validating DistilBERT\")\n","    with torch.no_grad():\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            start_positions = batch['start_positions'].to(device)\n","            end_positions = batch['end_positions'].to(device)\n","\n","            outputs = model(\n","                input_ids,\n","                attention_mask=attention_mask,\n","                start_positions=start_positions,\n","                end_positions=end_positions\n","            )\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","\n","            progress_bar.set_postfix({'loss': loss.item()})\n","\n","    return total_loss / len(val_loader)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:57:15.494866Z","iopub.status.busy":"2024-10-24T09:57:15.494254Z","iopub.status.idle":"2024-10-24T10:08:27.363840Z","shell.execute_reply":"2024-10-24T10:08:27.362696Z","shell.execute_reply.started":"2024-10-24T09:57:15.494819Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n"]},{"name":"stderr","output_type":"stream","text":["Training DistilBERT: 100%|██████████| 630/630 [05:06<00:00,  2.06it/s, loss=1.78] \n","Validating DistilBERT: 100%|██████████| 135/135 [00:28<00:00,  4.71it/s, loss=2.16]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 2.7911, Validation Loss: 2.1208\n","Model saved!\n","**************************************************\n","Epoch 2/2\n"]},{"name":"stderr","output_type":"stream","text":["Training DistilBERT: 100%|██████████| 630/630 [05:07<00:00,  2.05it/s, loss=1.35] \n","Validating DistilBERT: 100%|██████████| 135/135 [00:28<00:00,  4.70it/s, loss=1.91] \n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 1.4349, Validation Loss: 2.0061\n","Model saved!\n","**************************************************\n"]}],"source":["# Set optimizer\n","optimizer_distilbert = AdamW(distilbert_model.parameters(), lr=5e-5)\n","\n","# Training loop\n","num_epochs = 2\n","best_loss = float('inf')\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train_loss = train_distilbert(distilbert_model, train_loader_distilbert, optimizer_distilbert, device)\n","    val_loss = validate_distilbert(distilbert_model, val_loader_distilbert, device)\n","    print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        torch.save(distilbert_model.state_dict(), 'distilbert_qa_model.pth')\n","        print(\"Model saved!\")\n","    else:\n","        print(\"Validation Loss Increased. Model Not Saved.\")\n","    print(\"*\" * 50)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:10:38.447592Z","iopub.status.busy":"2024-10-24T10:10:38.447303Z","iopub.status.idle":"2024-10-24T10:10:38.456485Z","shell.execute_reply":"2024-10-24T10:10:38.455561Z","shell.execute_reply.started":"2024-10-24T10:10:38.447556Z"},"trusted":true},"outputs":[],"source":["# Testing function\n","def test_distilbert(model, test_loader, tokenizer, device):\n","    model.eval()\n","    all_predictions = []\n","    all_answers = []\n","    progress_bar = tqdm(test_loader, desc=\"Testing DistilBERT\")\n","    with torch.no_grad():\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            answers = batch['answer']\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            start_scores = outputs.start_logits\n","            end_scores = outputs.end_logits\n","\n","            for i in range(input_ids.shape[0]):\n","                start_index = torch.argmax(start_scores[i])\n","                end_index = torch.argmax(end_scores[i])\n","                prediction = tokenizer.decode(input_ids[i][start_index:end_index+1])\n","                all_predictions.append(prediction)\n","                all_answers.append(answers[i])\n","\n","    bleu_score = calculate_bleu(all_predictions, all_answers)\n","    return bleu_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a simple QA bot\n","def qa_bot_distilbert(context, question):\n","    inputs = distilbert_tokenizer.encode_plus(question, context, return_tensors='pt', max_length=512, truncation=True)\n","    input_ids = inputs['input_ids'].to(device)\n","    attention_mask = inputs['attention_mask'].to(device)\n","\n","    with torch.no_grad():\n","        outputs = distilbert_model(input_ids, attention_mask=attention_mask)\n","        start_scores = outputs.start_logits\n","        end_scores = outputs.end_logits\n","\n","    start_index = torch.argmax(start_scores)\n","    end_index = torch.argmax(end_scores)\n","    answer = distilbert_tokenizer.decode(input_ids[0][start_index:end_index+1])\n","    return answer\n","\n","# Example usage of the QA bot\n","context = test_data[0]['story']\n","question = test_data[0]['questions'][0]['input_text']\n","answer = qa_bot_distilbert(context, question)\n","print(f\"Question: {question}\")\n","print(f\"Answer: {answer}\")\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:12:42.393189Z","iopub.status.busy":"2024-10-24T10:12:42.392308Z","iopub.status.idle":"2024-10-24T10:12:46.615224Z","shell.execute_reply":"2024-10-24T10:12:46.614287Z","shell.execute_reply.started":"2024-10-24T10:12:42.393136Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"712b1cf9dbd84d0cb58b2d55a1d436ec","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75491e2ac85c402b9c6ae46f04c9b495","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f4b6b20943e4b979597b3381b7ae5ac","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54553ccf5a5f4f37b45e0ce32a27bff5","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3c7b2963fee48bfb3fbf4f48339607e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e1b17d9b863498591d60797b5a9324d","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6e3e933dab147d2b43c8795b9f5dd49","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize tokenizer and model\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token  # Add padding token\n","gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n","\n","# Prepare datasets and dataloaders\n","train_dataset_gpt2 = CoQADataset(train_data, gpt2_tokenizer, model_type='gpt2')\n","val_dataset_gpt2 = CoQADataset(val_data, gpt2_tokenizer, model_type='gpt2')\n","test_dataset_gpt2 = CoQADataset(test_data, gpt2_tokenizer, model_type='gpt2')\n","\n","train_loader_gpt2 = DataLoader(train_dataset_gpt2, batch_size=2, shuffle=True)\n","val_loader_gpt2 = DataLoader(val_dataset_gpt2, batch_size=2)\n","test_loader_gpt2 = DataLoader(test_dataset_gpt2, batch_size=2)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:12:50.778392Z","iopub.status.busy":"2024-10-24T10:12:50.777649Z","iopub.status.idle":"2024-10-24T10:12:50.784950Z","shell.execute_reply":"2024-10-24T10:12:50.784024Z","shell.execute_reply.started":"2024-10-24T10:12:50.778348Z"},"trusted":true},"outputs":[],"source":["# Training function\n","def train_gpt2(model, train_loader, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    progress_bar = tqdm(train_loader, desc=\"Training GPT-2\")\n","    for batch in progress_bar:\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(\n","            input_ids=input_ids,\n","            labels=labels\n","        )\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        progress_bar.set_postfix({'loss': loss.item()})\n","\n","    return total_loss / len(train_loader)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:12:55.716430Z","iopub.status.busy":"2024-10-24T10:12:55.715713Z","iopub.status.idle":"2024-10-24T10:12:55.722541Z","shell.execute_reply":"2024-10-24T10:12:55.721692Z","shell.execute_reply.started":"2024-10-24T10:12:55.716387Z"},"trusted":true},"outputs":[],"source":["# Validation function\n","def validate_gpt2(model, val_loader, device):\n","    model.eval()\n","    total_loss = 0\n","    progress_bar = tqdm(val_loader, desc=\"Validating GPT-2\")\n","    with torch.no_grad():\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(\n","                input_ids=input_ids,\n","                labels=labels\n","            )\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","\n","            progress_bar.set_postfix({'loss': loss.item()})\n","\n","    return total_loss / len(val_loader)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:12:58.648354Z","iopub.status.busy":"2024-10-24T10:12:58.647643Z","iopub.status.idle":"2024-10-24T10:27:14.093471Z","shell.execute_reply":"2024-10-24T10:27:14.092591Z","shell.execute_reply.started":"2024-10-24T10:12:58.648311Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1\n"]},{"name":"stderr","output_type":"stream","text":["Training GPT-2: 100%|██████████| 2520/2520 [13:25<00:00,  3.13it/s, loss=0.963]\n","Validating GPT-2: 100%|██████████| 540/540 [00:49<00:00, 10.88it/s, loss=2.19]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 2.2776, Validation Loss: 2.1235\n","Model saved!\n","**************************************************\n"]}],"source":["# Set optimizer\n","optimizer_gpt2 = AdamW(gpt2_model.parameters(), lr=5e-5)\n","\n","# Training loop\n","num_epochs = 1  # GPT-2 is heavy; adjust as per resources\n","best_loss = float('inf')\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train_loss = train_gpt2(gpt2_model, train_loader_gpt2, optimizer_gpt2, device)\n","    val_loss = validate_gpt2(gpt2_model, val_loader_gpt2, device)\n","    print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        torch.save(gpt2_model.state_dict(), 'gpt2_qa_model.pth')\n","        print(\"Model saved!\")\n","    else:\n","        print(\"Validation Loss Increased. Model Not Saved.\")\n","    print(\"*\" * 50)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:28:54.410198Z","iopub.status.busy":"2024-10-24T10:28:54.409586Z","iopub.status.idle":"2024-10-24T10:28:54.418085Z","shell.execute_reply":"2024-10-24T10:28:54.417106Z","shell.execute_reply.started":"2024-10-24T10:28:54.410156Z"},"trusted":true},"outputs":[],"source":["# Testing function\n","def test_gpt2(model, test_loader, tokenizer, device):\n","    model.eval()\n","    all_predictions = []\n","    all_answers = []\n","    progress_bar = tqdm(test_loader, desc=\"Testing GPT-2\")\n","    with torch.no_grad():\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(device)\n","            answers = batch['answer']\n","\n","            outputs = model.generate(\n","                input_ids=input_ids,\n","                max_length=521,\n","                do_sample=True,\n","                top_k=50,\n","                top_p=0.95,\n","                num_return_sequences=1\n","            )\n","\n","            for i in range(len(outputs)):\n","                generated = outputs[i][input_ids.size(1):]  # Skip the prompt part\n","                prediction = tokenizer.decode(generated, skip_special_tokens=True)\n","                all_predictions.append(prediction.strip())\n","                all_answers.append(answers[i])\n","\n","    bleu_score = calculate_bleu(all_predictions, all_answers)\n","    return bleu_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Test the model\n","bleu_score = test_gpt2(gpt2_model, test_loader_gpt2, gpt2_tokenizer, device)\n","print(f\"GPT-2 BLEU Score: {bleu_score:.4f}\")\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:30:34.920318Z","iopub.status.busy":"2024-10-24T10:30:34.919797Z","iopub.status.idle":"2024-10-24T10:30:35.008273Z","shell.execute_reply":"2024-10-24T10:30:35.007003Z","shell.execute_reply.started":"2024-10-24T10:30:34.920278Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: Who was a major influence on the theory on world travel?\n","Answer: Henry Ford\n"]}],"source":["# Create a simple QA bot\n","def qa_bot_gpt2(context, question):\n","    input_text = f\"Question: {question} Context: {context} Answer:\"\n","    input_ids = gpt2_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True).to(device)\n","\n","    with torch.no_grad():\n","        outputs = gpt2_model.generate(\n","            input_ids=input_ids,\n","            max_length=410,\n","            do_sample=True,\n","            top_k=50,\n","            top_p=0.95,\n","            num_return_sequences=1\n","        )\n","        generated = outputs[0][input_ids.size(1):]  # Skip the prompt part\n","        answer = gpt2_tokenizer.decode(generated, skip_special_tokens=True).strip()\n","    return answer\n","\n","# Example usage of the QA bot\n","context = test_data[0]['story']\n","question = test_data[0]['questions'][0]['input_text']\n","answer = qa_bot_gpt2(context, question)\n","print(f\"Question: {question}\")\n","print(f\"Answer: {answer}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Gradio UI"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:41:35.005702Z","iopub.status.busy":"2024-10-24T10:41:35.005353Z","iopub.status.idle":"2024-10-24T10:41:53.539622Z","shell.execute_reply":"2024-10-24T10:41:53.538663Z","shell.execute_reply.started":"2024-10-24T10:41:35.005670Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gradio\n","  Downloading gradio-5.3.0-py3-none-any.whl.metadata (15 kB)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Collecting anyio<5.0,>=3.0 (from gradio)\n","  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.3-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.4.2 (from gradio)\n","  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting httpx>=0.24.1 (from gradio)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting huggingface-hub>=0.25.1 (from gradio)\n","  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: jinja2<4.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.1.5)\n","Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (1.26.4)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.10.10-cp312-none-win_amd64.whl.metadata (51 kB)\n","     ---------------------------------------- 0.0/51.8 kB ? eta -:--:--\n","     ---------------------------------------- 51.8/51.8 kB 2.8 MB/s eta 0:00:00\n","Requirement already satisfied: packaging in c:\\users\\suyash tambe\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (24.0)\n","Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (10.3.0)\n","Requirement already satisfied: pydantic>=2.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.9.2)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (6.0.1)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.7.0-py3-none-win_amd64.whl.metadata (25 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.41.0-py3-none-any.whl.metadata (6.0 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.12.5)\n","Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (4.12.0)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: fsspec in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==1.4.2->gradio) (2024.6.0)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n","  Downloading websockets-12.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n","Requirement already satisfied: idna>=2.8 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n","Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio)\n","  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: certifi in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n","  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: filelock in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.15.3)\n","Requirement already satisfied: requests in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.2)\n","Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\suyash tambe\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (2.23.4)\n","Requirement already satisfied: click>=8.0.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n","Requirement already satisfied: colorama in c:\\users\\suyash tambe\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n","Requirement already satisfied: six>=1.5 in c:\\users\\suyash tambe\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\suyash tambe\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.1)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\suyash tambe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.3.0-py3-none-any.whl (56.7 MB)\n","   ---------------------------------------- 0.0/56.7 MB ? eta -:--:--\n","   ---------------------------------------- 0.3/56.7 MB 9.6 MB/s eta 0:00:06\n","    --------------------------------------- 1.0/56.7 MB 13.3 MB/s eta 0:00:05\n","   - -------------------------------------- 2.8/56.7 MB 22.3 MB/s eta 0:00:03\n","   -- ------------------------------------- 4.0/56.7 MB 28.8 MB/s eta 0:00:02\n","   --- ------------------------------------ 4.9/56.7 MB 26.0 MB/s eta 0:00:02\n","   ----- ---------------------------------- 7.1/56.7 MB 26.9 MB/s eta 0:00:02\n","   ------ --------------------------------- 8.6/56.7 MB 28.8 MB/s eta 0:00:02\n","   ------ --------------------------------- 9.7/56.7 MB 27.0 MB/s eta 0:00:02\n","   ------- -------------------------------- 10.7/56.7 MB 28.5 MB/s eta 0:00:02\n","   -------- ------------------------------- 11.6/56.7 MB 29.7 MB/s eta 0:00:02\n","   -------- ------------------------------- 12.7/56.7 MB 26.2 MB/s eta 0:00:02\n","   --------- ------------------------------ 13.7/56.7 MB 26.2 MB/s eta 0:00:02\n","   ---------- ----------------------------- 14.8/56.7 MB 26.2 MB/s eta 0:00:02\n","   ----------- ---------------------------- 15.9/56.7 MB 27.3 MB/s eta 0:00:02\n","   ------------ --------------------------- 17.0/56.7 MB 24.2 MB/s eta 0:00:02\n","   ------------ --------------------------- 18.1/56.7 MB 24.3 MB/s eta 0:00:02\n","   ------------- -------------------------- 19.2/56.7 MB 23.4 MB/s eta 0:00:02\n","   -------------- ------------------------- 20.2/56.7 MB 22.6 MB/s eta 0:00:02\n","   --------------- ------------------------ 21.3/56.7 MB 23.4 MB/s eta 0:00:02\n","   --------------- ------------------------ 22.5/56.7 MB 23.4 MB/s eta 0:00:02\n","   ---------------- ----------------------- 23.7/56.7 MB 24.2 MB/s eta 0:00:02\n","   ----------------- ---------------------- 24.8/56.7 MB 24.2 MB/s eta 0:00:02\n","   ------------------ --------------------- 26.0/56.7 MB 24.2 MB/s eta 0:00:02\n","   ------------------- -------------------- 27.1/56.7 MB 24.3 MB/s eta 0:00:02\n","   ------------------- -------------------- 28.2/56.7 MB 24.2 MB/s eta 0:00:02\n","   -------------------- ------------------- 29.3/56.7 MB 25.1 MB/s eta 0:00:02\n","   --------------------- ------------------ 30.5/56.7 MB 25.2 MB/s eta 0:00:02\n","   ---------------------- ----------------- 31.7/56.7 MB 24.2 MB/s eta 0:00:02\n","   ----------------------- ---------------- 32.8/56.7 MB 25.2 MB/s eta 0:00:01\n","   ----------------------- ---------------- 34.0/56.7 MB 25.2 MB/s eta 0:00:01\n","   ------------------------ --------------- 35.2/56.7 MB 25.2 MB/s eta 0:00:01\n","   ------------------------- -------------- 36.3/56.7 MB 25.2 MB/s eta 0:00:01\n","   -------------------------- ------------- 37.6/56.7 MB 26.2 MB/s eta 0:00:01\n","   --------------------------- ------------ 38.9/56.7 MB 26.2 MB/s eta 0:00:01\n","   ---------------------------- ----------- 40.1/56.7 MB 26.2 MB/s eta 0:00:01\n","   ----------------------------- ---------- 41.1/56.7 MB 25.2 MB/s eta 0:00:01\n","   ----------------------------- ---------- 42.4/56.7 MB 26.2 MB/s eta 0:00:01\n","   ------------------------------ --------- 43.5/56.7 MB 26.2 MB/s eta 0:00:01\n","   ------------------------------- -------- 44.5/56.7 MB 25.2 MB/s eta 0:00:01\n","   -------------------------------- ------- 45.8/56.7 MB 25.2 MB/s eta 0:00:01\n","   --------------------------------- ------ 47.0/56.7 MB 25.1 MB/s eta 0:00:01\n","   --------------------------------- ------ 48.1/56.7 MB 26.2 MB/s eta 0:00:01\n","   ---------------------------------- ----- 49.4/56.7 MB 25.2 MB/s eta 0:00:01\n","   ----------------------------------- ---- 50.5/56.7 MB 26.2 MB/s eta 0:00:01\n","   ------------------------------------ --- 51.7/56.7 MB 25.2 MB/s eta 0:00:01\n","   ------------------------------------- -- 53.1/56.7 MB 26.2 MB/s eta 0:00:01\n","   -------------------------------------- - 54.2/56.7 MB 26.2 MB/s eta 0:00:01\n","   ---------------------------------------  55.3/56.7 MB 26.2 MB/s eta 0:00:01\n","   ---------------------------------------  56.1/56.7 MB 26.2 MB/s eta 0:00:01\n","   ---------------------------------------  56.7/56.7 MB 26.2 MB/s eta 0:00:01\n","   ---------------------------------------  56.7/56.7 MB 26.2 MB/s eta 0:00:01\n","   ---------------------------------------- 56.7/56.7 MB 19.8 MB/s eta 0:00:00\n","Downloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n","   ---------------------------------------- 0.0/319.8 kB ? eta -:--:--\n","   --------------------------------------- 319.8/319.8 kB 19.3 MB/s eta 0:00:00\n","Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n","   ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n","   ---------------------------------------- 90.4/90.4 kB ? eta 0:00:00\n","Downloading fastapi-0.115.3-py3-none-any.whl (94 kB)\n","   ---------------------------------------- 0.0/94.6 kB ? eta -:--:--\n","   ---------------------------------------- 94.6/94.6 kB 5.6 MB/s eta 0:00:00\n","Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n","   ---------------------------------------- 76.4/76.4 kB 4.4 MB/s eta 0:00:00\n","Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","   ---------------------------------------- 0.0/78.0 kB ? eta -:--:--\n","   ---------------------------------------- 78.0/78.0 kB 4.5 MB/s eta 0:00:00\n","Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n","   ---------------------------------------- 0.0/447.4 kB ? eta -:--:--\n","   --------------------------------------- 447.4/447.4 kB 27.3 MB/s eta 0:00:00\n","Downloading orjson-3.10.10-cp312-none-win_amd64.whl (139 kB)\n","   ---------------------------------------- 0.0/139.4 kB ? eta -:--:--\n","   ---------------------------------------- 139.4/139.4 kB 8.1 MB/s eta 0:00:00\n","Downloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n","Downloading ruff-0.7.0-py3-none-win_amd64.whl (9.4 MB)\n","   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n","   ------ --------------------------------- 1.4/9.4 MB 30.1 MB/s eta 0:00:01\n","   ----------- ---------------------------- 2.6/9.4 MB 27.8 MB/s eta 0:00:01\n","   ---------------- ----------------------- 3.9/9.4 MB 27.7 MB/s eta 0:00:01\n","   --------------------- ------------------ 5.0/9.4 MB 26.6 MB/s eta 0:00:01\n","   --------------------------- ------------ 6.3/9.4 MB 26.9 MB/s eta 0:00:01\n","   -------------------------------- ------- 7.6/9.4 MB 27.0 MB/s eta 0:00:01\n","   ------------------------------------- -- 8.9/9.4 MB 26.9 MB/s eta 0:00:01\n","   ---------------------------------------- 9.4/9.4 MB 26.0 MB/s eta 0:00:00\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.41.0-py3-none-any.whl (73 kB)\n","   ---------------------------------------- 0.0/73.2 kB ? eta -:--:--\n","   ---------------------------------------- 73.2/73.2 kB 3.9 MB/s eta 0:00:00\n","Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n","   ---------------------------------------- 0.0/63.7 kB ? eta -:--:--\n","   ---------------------------------------- 63.7/63.7 kB ? eta 0:00:00\n","Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n","   ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n","Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n","Downloading websockets-12.0-cp312-cp312-win_amd64.whl (124 kB)\n","   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n","   ---------------------------------------- 125.0/125.0 kB ? eta 0:00:00\n","Installing collected packages: pydub, websockets, tomlkit, sniffio, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, huggingface-hub, httpcore, anyio, starlette, httpx, gradio-client, fastapi, gradio\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.23.4\n","    Uninstalling huggingface-hub-0.23.4:\n","      Successfully uninstalled huggingface-hub-0.23.4\n","Successfully installed aiofiles-23.2.1 anyio-4.6.2.post1 fastapi-0.115.3 ffmpy-0.4.0 gradio-5.3.0 gradio-client-1.4.2 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.1 orjson-3.10.10 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.0 semantic-version-2.10.0 sniffio-1.3.1 starlette-0.41.0 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.1.1 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install gradio\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:42:46.220939Z","iopub.status.busy":"2024-10-24T10:42:46.220539Z","iopub.status.idle":"2024-10-24T10:42:49.918755Z","shell.execute_reply":"2024-10-24T10:42:49.917962Z","shell.execute_reply.started":"2024-10-24T10:42:46.220900Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, DistilBertTokenizer, DistilBertForQuestionAnswering, T5ForConditionalGeneration,T5Tokenizer\n","import gradio as gr"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["# Load the GPT-2 model and tokenizer\n","gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')  # Initialize GPT-2 model\n","gpt2_model.load_state_dict(torch.load(r'C:\\Users\\Suyash Tambe\\Desktop\\NLP Lab\\gpt2_qa_model.pth'))  # Load trained weights\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')  # Default GPT-2 tokenizer"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:35:36.324264Z","iopub.status.busy":"2024-10-24T10:35:36.323587Z","iopub.status.idle":"2024-10-24T10:35:36.679286Z","shell.execute_reply":"2024-10-24T10:35:36.678335Z","shell.execute_reply.started":"2024-10-24T10:35:36.324219Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"547cc615dad340bf8a6dbf4db22e863c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Suyash Tambe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Suyash Tambe\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  size (`size`):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8134999162040528211293266d45175","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1348925b0db446393423fb8d19366e4","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c25f556d60084e8f9a60621c33983179","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c706f34f32064d46bb1d34e8a207c679","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["distilbert_model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')  # Initialize model\n","distilbert_model.load_state_dict(torch.load(r'C:\\Users\\Suyash Tambe\\Desktop\\NLP Lab\\distilbert_qa_model.pth'))  # Load trained weights\n","distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')  # Default tokenizer\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"307e85792ee04182bfee5f0c94dea290","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf7c037482de451686b7cd3f6246ac32","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]}],"source":["# Load the T5 model and tokenizer\n","t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')  # Initialize T5 model\n","t5_model.load_state_dict(torch.load(r'C:\\Users\\Suyash Tambe\\Desktop\\NLP Lab\\t5_qa_model.pth'))  # Load trained weights\n","t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')  # Default T5 tokenizer"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:37:05.838489Z","iopub.status.busy":"2024-10-24T10:37:05.837920Z","iopub.status.idle":"2024-10-24T10:37:05.847914Z","shell.execute_reply":"2024-10-24T10:37:05.846970Z","shell.execute_reply.started":"2024-10-24T10:37:05.838447Z"},"trusted":true},"outputs":[],"source":["# Inference functions for the models\n","def qa_bot_gpt2(context, question):\n","    input_text = f\"Question: {question} Context: {context} Answer:\"\n","    input_ids = gpt2_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True).to('cpu')\n","\n","    with torch.no_grad():\n","        outputs = gpt2_model.generate(\n","            input_ids=input_ids,\n","            max_length=410,\n","            do_sample=True,\n","            top_k=50,\n","            top_p=0.95,\n","            num_return_sequences=1\n","        )\n","        generated = outputs[0][input_ids.size(1):]  # Skip the prompt part\n","        answer = gpt2_tokenizer.decode(generated, skip_special_tokens=True).strip()\n","    return answer\n","\n","def qa_bot_distilbert(context, question):\n","    inputs = distilbert_tokenizer.encode_plus(question, context, return_tensors='pt')\n","    input_ids = inputs['input_ids'].to('cpu')\n","    attention_mask = inputs['attention_mask'].to('cpu')\n","    \n","    outputs = distilbert_model(input_ids, attention_mask=attention_mask)\n","    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n","\n","    # Get the most likely answer\n","    answer_start = torch.argmax(start_scores)\n","    answer_end = torch.argmax(end_scores) + 1\n","    answer = distilbert_tokenizer.convert_tokens_to_string(\n","        distilbert_tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end])\n","    )\n","    return answer\n","\n","def qa_bot_t5(context, question):\n","    input_text = f\"question: {question} context: {context}\"\n","    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\").to('cpu')\n","\n","    with torch.no_grad():\n","        outputs = t5_model.generate(input_ids=input_ids, max_length=512, num_beams=4, early_stopping=True)\n","        answer = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return answer"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:37:15.894789Z","iopub.status.busy":"2024-10-24T10:37:15.894189Z","iopub.status.idle":"2024-10-24T10:37:15.899605Z","shell.execute_reply":"2024-10-24T10:37:15.898685Z","shell.execute_reply.started":"2024-10-24T10:37:15.894747Z"},"trusted":true},"outputs":[],"source":["# Main function to handle model selection and question answering\n","def generate_answer(model_name, article, question):\n","    if model_name == \"GPT-2\":\n","        return qa_bot_gpt2(article, question)\n","    elif model_name == \"DistilBERT\":\n","        return qa_bot_distilbert(article, question)\n","    elif model_name == \"T5\":\n","        return qa_bot_t5(article, question)\n","    else:\n","        return \"Model not recognized.\""]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:40:13.194816Z","iopub.status.busy":"2024-10-24T10:40:13.193912Z","iopub.status.idle":"2024-10-24T10:40:13.200886Z","shell.execute_reply":"2024-10-24T10:40:13.199931Z","shell.execute_reply.started":"2024-10-24T10:40:13.194774Z"},"trusted":true},"outputs":[],"source":["# Create Gradio Interface\n","def create_interface():\n","    # Dropdown for model selection\n","    model_dropdown = gr.Dropdown(choices=[\"GPT-2\", \"DistilBERT\", \"T5\"], label=\"Choose a Model\")\n","\n","    # Text boxes for article and question inputs\n","    article_input = gr.Textbox(lines=10, placeholder=\"Enter article here\", label=\"Article\")\n","    question_input = gr.Textbox(lines=2, placeholder=\"Enter your question\", label=\"Question\")\n","    \n","    # Output text box for the answer\n","    answer_output = gr.Textbox(label=\"Answer\")\n","    \n","    # Create the Gradio interface\n","    interface = gr.Interface(\n","        fn=generate_answer,\n","        inputs=[model_dropdown, article_input, question_input],\n","        outputs=answer_output,\n","        title=\"Model-based Q&A\",\n","        description=\"Select a model (GPT-2, DistilBERT, or T5), input an article, ask a question, and receive an answer.\",\n","    )\n","    \n","    return interface"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:40:16.817967Z","iopub.status.busy":"2024-10-24T10:40:16.817379Z","iopub.status.idle":"2024-10-24T10:40:16.870185Z","shell.execute_reply":"2024-10-24T10:40:16.867472Z","shell.execute_reply.started":"2024-10-24T10:40:16.817915Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["* Running on local URL:  http://127.0.0.1:7861\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"text/html":["<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Launch the UI\n","if __name__ == \"__main__\":\n","    ui = create_interface()\n","    ui.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5934473,"sourceId":9703788,"sourceType":"datasetVersion"},{"datasetId":5938912,"sourceId":9709618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
